{"cells":[{"cell_type":"markdown","source":["# Overview"],"metadata":{"id":"z3paB6LdRPdz"}},{"cell_type":"markdown","source":["Clean messy data loaded from `.xlsm` file and export it as a cleaned `.csv`"],"metadata":{"id":"TalLaFlNRSGu"}},{"cell_type":"markdown","source":["***This notebook will not run correctly.***\n","\n","*It requires the original dataset which is witheld for privacy reasons.*"],"metadata":{"id":"yBpYG2es_1M8"}},{"cell_type":"markdown","metadata":{"id":"uraI93bw6iWI"},"source":["# Imports and data loading"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"uBTAn0kGsqz9","executionInfo":{"status":"ok","timestamp":1668645999497,"user_tz":300,"elapsed":172,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# Filesystem\n","from google.colab import drive\n","\n","# Data manipulation\n","import pandas as pd\n","import numpy as np\n","\n","# Data cleaning\n","import re\n","\n","# Analysis\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["The .xlsm file format is effectively a list of .csv files. The years we are interested in is 2010 to 2020 since they are all pretty similar and will be relatively easy to clean."],"metadata":{"id":"OQL2iblfGY3Q"}},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10117,"status":"ok","timestamp":1668646009859,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"},"user_tz":300},"id":"SnIPwyWxsv2a","outputId":"fda621eb-e135-4164-e97a-906ec2636d8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Load xlsm\n","drive.mount('/content/drive', force_remount=True);\n","path_to_folder = 'drive/My Drive/Colab Notebooks/Fishing/data/'\n","xlsm = pd.read_excel(path_to_folder + 'fishing2.xlsm', sheet_name=None);"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"Ttir3J_5tWn_","executionInfo":{"status":"ok","timestamp":1668646009861,"user_tz":300,"elapsed":20,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# List is a specific order since some cleaning is index based\n","years = ['2015', '2014', '2013', '2012', '2011', '2010',\n","         '2020', '2019', '2018', '2017', '2016', ]\n","\n","# Combine all years\n","dfs = [xlsm[year] for year in years]\n","df = pd.concat(dfs)\n","df.reset_index(drop=True, inplace=True);"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"Jjl3WcT_Sv7L","executionInfo":{"status":"ok","timestamp":1668646009861,"user_tz":300,"elapsed":19,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# # Show data\n","pd.set_option(\"max_columns\", None)\n","# dfs"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"jrCi6DCcS2Tr","executionInfo":{"status":"ok","timestamp":1668646009863,"user_tz":300,"elapsed":21,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["pd.reset_option(\"max_columns\")"]},{"cell_type":"markdown","metadata":{"id":"GS5moTfX6r_Y"},"source":["# Cleaning data"]},{"cell_type":"markdown","source":["There is a lot of work to do with this dataset. There are a lot of `NaN` values and a lot of messy columns. Luckily, for some of the columns like 'Fish Size' they were simply renamed/reloacted from other columns like 'Fish Length'. Unfortunately, a lot of the information from the more clean columns like 'Start Time' and 'End Time' were originally inconsistently formatted text locatted in the 'Narrative' column."],"metadata":{"id":"6eolkuHRHO1y"}},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1668646009864,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"},"user_tz":300},"id":"7J-XvjB438Kz","outputId":"a979a54b-1b4a-4c67-f7ab-3ca671e87502"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Year  Month  Day  Start Time  End Time  Tally  Crew Members  Location  \\\n","Year                                                                          \n","2010     0      0    0         244       244    244           244         0   \n","2011     0      0    0         333       333    333           333         0   \n","2012     0      0    0         191       191    191           191         0   \n","2013     0      0    0           0         0      0             0         0   \n","2014     0      0    0           0         0      0             0         0   \n","2015     0      0    0           0         0      0             0         0   \n","2016     0      0    0           0         0      0             0         0   \n","2017     0      0    0           0         0      0             0         0   \n","2018     0      0    0           0         0      0             0         0   \n","2019     0      0    0           0         0      0             0         0   \n","2020     0      0    0           0         0      0             0         0   \n","\n","      Air Temp  Weather  Wind Level  Wind Direction  Surface Cond  \\\n","Year                                                                \n","2010         0        0           0               0           244   \n","2011         0        0           0               0           333   \n","2012         0        0           0               0           191   \n","2013         0        0           0               0             0   \n","2014         0        0           0               0             0   \n","2015         0        0           0               0             0   \n","2016         0        0           0               0             0   \n","2017         0        0           0               0             0   \n","2018         0        0           0               0             0   \n","2019         0        0           0               0             0   \n","2020         0        0           0               0             0   \n","\n","      Trolling Speed  Water Depth  Lure  Method  Setup  Additional Info  \\\n","Year                                                                      \n","2010               0            0   244       0      0              244   \n","2011               0            0   333       0      0              333   \n","2012               0            0   191       0      0              191   \n","2013               0            0     0       0      0              199   \n","2014               1            1     1       1      1               82   \n","2015               0            0     0       0      0               85   \n","2016               0            0     0       0      0              133   \n","2017               1            1     1       1      4               29   \n","2018               0            0     0       0      0               68   \n","2019               0            0     0       0      2              100   \n","2020              30            0     0       0      0               15   \n","\n","      Fish Type  Fish Size  Narrative  Time  Water Temp  Waves  Fish Length  \\\n","Year                                                                          \n","2010          0        244          0     0           0      0            0   \n","2011          0        333          0     0           0      0            0   \n","2012          0        191          0     0           0      0            0   \n","2013          0          0        227   235         235    235          235   \n","2014          1          1        135   163         163    163          163   \n","2015          0          0        148   165         165    165          165   \n","2016          0          1        117   152         152    152          152   \n","2017          1          1         30    54          54     54           54   \n","2018          0          0        147   188         188    188          188   \n","2019          0          0        186   195         195    195          195   \n","2020          0          0         27    30          30     30           30   \n","\n","      Lure Type  Lure Brand  Lure Name/Color  Attractor  Surface Temp  \n","Year                                                                   \n","2010          0           0                0          0           244  \n","2011          0           0                0          0           333  \n","2012          0           0                0          0           191  \n","2013        235         235              235        235           235  \n","2014        163         163              163        163           163  \n","2015        165         165              165        165           165  \n","2016        152         152              152        152           152  \n","2017         54          54               54         54            54  \n","2018        188         188              188        188           188  \n","2019        195         195              195        195           195  \n","2020         30          30               30         30             0  "],"text/html":["\n","  <div id=\"df-3bb66eac-e792-4918-adcf-45e4182ad5c4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>Start Time</th>\n","      <th>End Time</th>\n","      <th>Tally</th>\n","      <th>Crew Members</th>\n","      <th>Location</th>\n","      <th>Air Temp</th>\n","      <th>Weather</th>\n","      <th>Wind Level</th>\n","      <th>Wind Direction</th>\n","      <th>Surface Cond</th>\n","      <th>Trolling Speed</th>\n","      <th>Water Depth</th>\n","      <th>Lure</th>\n","      <th>Method</th>\n","      <th>Setup</th>\n","      <th>Additional Info</th>\n","      <th>Fish Type</th>\n","      <th>Fish Size</th>\n","      <th>Narrative</th>\n","      <th>Time</th>\n","      <th>Water Temp</th>\n","      <th>Waves</th>\n","      <th>Fish Length</th>\n","      <th>Lure Type</th>\n","      <th>Lure Brand</th>\n","      <th>Lure Name/Color</th>\n","      <th>Attractor</th>\n","      <th>Surface Temp</th>\n","    </tr>\n","    <tr>\n","      <th>Year</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2010</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>244</td>\n","      <td>244</td>\n","      <td>244</td>\n","      <td>244</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>244</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>244</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>244</td>\n","      <td>0</td>\n","      <td>244</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>244</td>\n","    </tr>\n","    <tr>\n","      <th>2011</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>333</td>\n","      <td>333</td>\n","      <td>333</td>\n","      <td>333</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>333</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>333</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>333</td>\n","      <td>0</td>\n","      <td>333</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>333</td>\n","    </tr>\n","    <tr>\n","      <th>2012</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>191</td>\n","      <td>191</td>\n","      <td>191</td>\n","      <td>191</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>191</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>191</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>191</td>\n","      <td>0</td>\n","      <td>191</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>191</td>\n","    </tr>\n","    <tr>\n","      <th>2013</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>199</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>227</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","    </tr>\n","    <tr>\n","      <th>2014</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>135</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>163</td>\n","      <td>163</td>\n","    </tr>\n","    <tr>\n","      <th>2015</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>85</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>148</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","      <td>165</td>\n","    </tr>\n","    <tr>\n","      <th>2016</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>133</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>117</td>\n","      <td>152</td>\n","      <td>152</td>\n","      <td>152</td>\n","      <td>152</td>\n","      <td>152</td>\n","      <td>152</td>\n","      <td>152</td>\n","      <td>152</td>\n","      <td>152</td>\n","    </tr>\n","    <tr>\n","      <th>2017</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>29</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>30</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th>2018</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>68</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>147</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>188</td>\n","    </tr>\n","    <tr>\n","      <th>2019</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>100</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>186</td>\n","      <td>195</td>\n","      <td>195</td>\n","      <td>195</td>\n","      <td>195</td>\n","      <td>195</td>\n","      <td>195</td>\n","      <td>195</td>\n","      <td>195</td>\n","      <td>195</td>\n","    </tr>\n","    <tr>\n","      <th>2020</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>27</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bb66eac-e792-4918-adcf-45e4182ad5c4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3bb66eac-e792-4918-adcf-45e4182ad5c4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3bb66eac-e792-4918-adcf-45e4182ad5c4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":45}],"source":["# # See where the nans are\n","pd.set_option(\"max_columns\", None)\n","df.isnull().groupby(df['Year']).sum()"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"8rki9Tp87Cyd","executionInfo":{"status":"ok","timestamp":1668646010068,"user_tz":300,"elapsed":214,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["pd.reset_option(\"max_columns\")"]},{"cell_type":"code","source":["# Remove rows with a lot of nans\n","df.drop([265, 1744], inplace=True)"],"metadata":{"id":"Z-U3d0YEEZfS","executionInfo":{"status":"ok","timestamp":1668646010069,"user_tz":300,"elapsed":6,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Initialize dataframe\n","df_clean = pd.DataFrame()"],"metadata":{"id":"4hB7nI4ubgbG","executionInfo":{"status":"ok","timestamp":1668646010071,"user_tz":300,"elapsed":8,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IkMY66F36tbk"},"source":["## Time based columns"]},{"cell_type":"markdown","source":["### Starting, ending, and caught times"],"metadata":{"id":"3Q3YSnJmTZoX"}},{"cell_type":"markdown","metadata":{"id":"CNEJ7Ox0Uo-n"},"source":["For 2013 to 2020 the start and stop times have their own column, and there are no times marked for when a fish is caught. \n","\n","For 2010 to 2012 there is only a column for the time a fish is caught. For most of the entries, the start and stop times are discussed in the narrative. However, the formatting is not consistent and some entries do not have a narrative column.\n","\n","These values are important to get right since our main metric `hook_rate` is dependant on these values being accurate."]},{"cell_type":"code","source":["# Fix improperly formatted 'Start Time' entry\n","df.loc[df['Start Time'] == '0:500', 'Start Time'] = '05:00'\n","df.loc[367:371, ['Start Time', 'End Time']] = df.loc[367:371, ['End Time', 'Start Time']].values"],"metadata":{"id":"AKkD9axurctn","executionInfo":{"status":"ok","timestamp":1668646010071,"user_tz":300,"elapsed":7,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# Convert column to a datetime object\n","df_clean['date'] = pd.to_datetime(df[['Year','Month','Day']])\n","date_stamp = df['Year'].astype(str) + \\\n","             '-' + df['Month'].astype(str) + \\\n","             '-' + df['Day'].astype(str)\n","df_clean['start_time'] = pd.to_datetime(date_stamp + ' ' + df['Start Time'])\n","df_clean['end_time'] = pd.to_datetime(date_stamp + ' ' + df['End Time'])\n","df_clean['time'] = pd.to_datetime(date_stamp + ' ' + df['Time'])"],"metadata":{"id":"_twuSMAcbtfB","executionInfo":{"status":"ok","timestamp":1668646010072,"user_tz":300,"elapsed":8,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0GbtoXzoWAQ5"},"source":["#### Regex extraction for start / end times"]},{"cell_type":"markdown","metadata":{"id":"ORgDrfImZDRb"},"source":["We can use regex to extract the `start_time` and `end_time` from the 'Narrative' column. We can take advantage of the fact that for the years 2010-2012 the first two sets of numbers are the start and end time for the fishing trip. There are some exceptions to this where the tally comes first, but we can remove the tallies easily since they have a very consistent format: `{caught} for {hooked}`."]},{"cell_type":"code","source":["# Extract start and stop times from 'Narrative' column\n","\n","# Select where 'Start Time' doesn't exist (selects years 2010-2012)\n","temp1 = df.loc[df['Start Time'].isna(), 'Narrative'].copy()\n","\n","# Removes colons and tally counts\n","temp2 = temp1.str.replace(':','')\n","temp3 = temp2.str.replace(r'(\\d+) for (\\d+)', '', regex=True)\n","\n","# Extract start and end times\n","temp4 = temp3.str.extract(r\"(\\d+)\\D+(\\d+)\")\n","\n","# Convert times to millitary time (i.e. 14:30)\n","def fix_time(time):\n","\n","    if time is np.nan:\n","        return np.nan\n","\n","    # Catches hours formatted like '1' or '14'\n","    if len(time) < 3:\n","        temp = f\"{time :{'0'}>2}\"\n","        time = f\"{temp :{'0'}<4}\"\n","\n","    # Catches hours and minutes formated like '830'\n","    elif len(time) == 3:\n","        time = '0' + time\n","\n","    # Insert colon so conversion to datetime works and return\n","    return time[:2] + ':' + time[2:]\n","    \n","start_times = temp4[0].apply(fix_time)\n","start_times = pd.to_datetime(date_stamp + ' ' + start_times)\n","end_times = temp4[1].apply(fix_time)\n","end_times = pd.to_datetime(date_stamp + ' ' + end_times)\n","\n","# Set start and stop times as properly formatted datetimes\n","df_clean.loc[df['Start Time'].isna(), 'start_time'] = start_times\n","df_clean.loc[df['Start Time'].isna(), 'end_time'] = end_times"],"metadata":{"id":"iVm_CZlAx0B6","executionInfo":{"status":"ok","timestamp":1668646010072,"user_tz":300,"elapsed":8,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TVGb25aMV5_7"},"source":["#### Imputing start / end times"]},{"cell_type":"markdown","metadata":{"id":"kjpbgYxP8f4W"},"source":["For times that do not appear in `Start Time`, `End Time`, or `Narrative` we can impute them using the non nan `start_time` and `end_time` values.\n","\n","For days with a single fish caught, the best solution is to calculate the average time, `time_delta_avg`, between `start_time` and `end_time`, then calculate `start_time` as `time` - `time_delta_avg / 2` and `end_time` as `time` + `time_delta_avg / 2`. Applying the same strategy for days with multiple fish caught would result in different values for `start_time` and `end_time`. The best solution is to use the time that the first fish is caught as `start_time` and the time of the last fish as `end_time`. If the time range is smaller than `time_delta_avg`, calculate the difference between the time deltas. Subtract half of the difference from the first time, and add half of the difference to the last.\n","\n","There are so few entries that require imputation that any biasing is minimal."]},{"cell_type":"code","source":["# Impute start and end times for 1087 to 1107 (some missing columns from 2010)\n","\n","# Calculate average time fished in 2010\n","mask = (df['Year'] == 2010)\n","time_deltas = df_clean.loc[mask, 'end_time'] - df_clean.loc[mask, 'start_time']\n","mean_time_delta = time_deltas.mean()\n","\n","# Use time of earliest and last fish caught as default 'start_time' and 'end_time'\n","start_times = df_clean.groupby('date').first()['time']\n","end_times = df_clean.groupby('date').last()['time']\n","\n","# Calculate time_deltas of new fish\n","time_deltas = end_times - start_times\n","\n","# Select where new time_gaps smaller than mean\n","time_gaps = np.timedelta64(220, 'm') - time_deltas\n","time_gaps = time_gaps * (time_gaps > np.timedelta64(0, 'm'))\n","\n","# Impute new start and end times\n","time_diff = time_gaps / 2\n","start_times = start_times - time_diff / 2\n","end_times = end_times + time_diff / 2\n","\n","# Set new time ranges only where nans are\n","def impute_times(row):\n","    if pd.isnull(row['start_time']):\n","        row['start_time'] = start_times[row['date']]\n","    if pd.isnull(row['end_time']):\n","        row['end_time'] = end_times[row['date']]\n","    return row\n","df_clean = df_clean.apply(impute_times, axis=1)"],"metadata":{"id":"yRaozBbkGJIp","executionInfo":{"status":"ok","timestamp":1668646010572,"user_tz":300,"elapsed":508,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["### Imputing time"],"metadata":{"id":"0uozlFQXNZEx"}},{"cell_type":"markdown","source":["Use `start_time` and `end_time` to impute fish caught `time` using the middle of the range."],"metadata":{"id":"fZxxckiOR0Bq"}},{"cell_type":"code","source":["# Impute 'time' for rows with 'end_time' and 'start_time'\n","time_deltas = df_clean['end_time'] - df_clean['start_time'] \n","df_clean.loc[df['Time'].isna(), 'time'] = df_clean['start_time'] + time_deltas / 2"],"metadata":{"id":"ceXJaAXnTdsV","executionInfo":{"status":"ok","timestamp":1668646010573,"user_tz":300,"elapsed":9,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["### Year, month"],"metadata":{"id":"FMRJvfstibHt"}},{"cell_type":"code","execution_count":54,"metadata":{"id":"XwjLLkgo9p70","executionInfo":{"status":"ok","timestamp":1668646010573,"user_tz":300,"elapsed":8,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# Add year and month for trends between years and within years\n","df_clean['year'] = df['Year']\n","df_clean['month'] = df['Month']"]},{"cell_type":"markdown","source":["### Hours fishing"],"metadata":{"id":"UMNlLPpXKHd1"}},{"cell_type":"code","source":["# Time between start and stop\n","time_deltas = df_clean['end_time'] - df_clean['start_time']\n","df_clean['hours_fishing'] = time_deltas.apply(lambda x: x.seconds / (60 * 60))"],"metadata":{"id":"CrWfXInuKKLk","executionInfo":{"status":"ok","timestamp":1668646010573,"user_tz":300,"elapsed":7,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["### Time periods"],"metadata":{"id":"G8KOgIiS19x6"}},{"cell_type":"markdown","source":["Whether the fish was caught in the morning, afternoon, evening, or at night. This implementation does not account for daylights saving or the change in time of sunset and sunrise. "],"metadata":{"id":"avTJVugYXnNR"}},{"cell_type":"code","source":["# Get time periods of the day\n","\n","def time_to_period(row):\n","\n","    # Morning is between 6am and 12pm\n","    if row.hour >= 6 and row.hour < 12:\n","        return 'morning'\n","\n","    # Afternooon is between 12pm and 6pm\n","    elif row.hour >= 12 and row.hour < 18:\n","        return 'afternoon'\n","\n","    # Evening is between 6pm and 9pm\n","    elif row.hour >= 18 and row.hour < 21:\n","        return 'evening'\n","\n","    # Night is between 9pm and 6am\n","    elif row.hour >= 21 and row.hour <= 24:\n","        return 'night'\n","    elif row.hour >= 0 and row.hour <= 6:\n","        return 'night'\n","        \n","df_clean['time_period'] = df_clean['time'].apply(time_to_period)"],"metadata":{"id":"VKGM-nDg2-rb","executionInfo":{"status":"ok","timestamp":1668646010574,"user_tz":300,"elapsed":8,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["### Seasons"],"metadata":{"id":"sXvDAukaykX7"}},{"cell_type":"markdown","source":["Whether the fish was caught in winter, spring, summer, or fall. These categories are a bit arbitrary. "],"metadata":{"id":"qmlhA-J5YKc8"}},{"cell_type":"code","source":["# Get seasons of the year\n","\n","def time_to_period(row):\n","\n","    # Winter is between December and March\n","    if row.month >= 1 and row.month < 3:\n","        return 'winter'\n","    elif row.month == 12:\n","            return 'winter'\n","\n","    # Spring is between March and June\n","    elif row.month >= 3 and row.month < 6:\n","        return 'spring'\n","\n","    # Summer is between June and September\n","    elif row.month >= 6 and row.month < 9:\n","        return 'summer'\n","\n","    # Fall is between September and December\n","    elif row.month >= 9 and row.month < 12:\n","        return 'fall'\n","    \n","df_clean['season'] = df_clean['time'].apply(time_to_period)"],"metadata":{"id":"N3nTJwLfylU8","executionInfo":{"status":"ok","timestamp":1668646010574,"user_tz":300,"elapsed":7,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X_6Xg0MNUKRc"},"source":["## Tally (fish caught and hooked)"]},{"cell_type":"markdown","metadata":{"id":"Ro0ZvQjCFGNW"},"source":["The ideal metric would be the number of fish hooked for every day fishing, even if you didn't catch anything. However, in this dataset if no fish are caught then there is no entry. The next best metric is the number of fish hooked per hour spent fishing. This will at least give us a metric for if a day was good or bad for fishing."]},{"cell_type":"code","execution_count":58,"metadata":{"id":"ylHFJJPBcKQm","executionInfo":{"status":"ok","timestamp":1668646011022,"user_tz":300,"elapsed":455,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# Use extract() to get tallies from narrative\n","tallies = df.loc[df['Tally'].isna(), 'Narrative'].str.extract('(\\d+\\s?for\\s?\\d+)')\n","\n","# Split the tally into caught and hooked\n","split1 = df.loc[df['Year'] > 2012, 'Tally'].str.split('for', expand=True)\n","split2 = tallies[0].str.split('for', expand=True)\n","caught = pd.concat((split1[0], split2[0]))\n","hooked = pd.concat((split1[1], split2[1]))\n","\n","# Convert to float to handle NaNs properly\n","df_clean['caught'] = caught.astype(float)\n","df_clean['hooked'] = hooked.astype(float)\n","\n","# Impute hooked and caught to be the number of entries \n","# (number of fish caught)\n","caught = df_clean[df_clean['caught'].isna()].groupby('date').size()\n","def impute_caught_and_hooked(row):\n","    if pd.isnull(row['caught']):\n","        row['caught'] = caught[row['date']]\n","    if pd.isnull(row['hooked']):\n","        row['hooked'] = caught[row['date']] \n","    return row\n","df_clean.loc[df_clean['caught'].isna()] = df_clean[df_clean['caught'].isna()].apply(impute_caught_and_hooked, axis=1)"]},{"cell_type":"markdown","metadata":{"id":"F27S5AV07oRg"},"source":["## Air temp"]},{"cell_type":"code","source":["# Convert ambiguous temps to discrete temps\n","df_clean['air_temp'] = df['Air Temp'].astype(str)\n","air_temps = df['Air Temp'].astype(str)\n","temps = {\n","    \"30's\": 35,\n","    \"40's\": 45,\n","    \"50's\": 55,\n","    \"60's\": 65,\n","    \"70's\": 75,\n","    \"80's\": 85\n","}\n","for temp in temps:\n","    df_clean.loc[air_temps.str.contains(temp, case=False), 'air_temp'] = temps[temp]\n","df_clean['air_temp'] = df_clean['air_temp'].astype(int)"],"metadata":{"id":"Q-PLp4GCxlRs","executionInfo":{"status":"ok","timestamp":1668646011023,"user_tz":300,"elapsed":12,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_6IAmOwlUW8G"},"source":["## Weather"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"-AFnMyXW1A24","executionInfo":{"status":"ok","timestamp":1668646011023,"user_tz":300,"elapsed":10,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# Set weather\n","df_clean['weather'] = df['Weather']"]},{"cell_type":"markdown","metadata":{"id":"VmSj_y1_Uhl8"},"source":["## Wind"]},{"cell_type":"markdown","source":["Wind-level is close to but not eactly linear with the actual speed. Each level is about a change in windspeed of between three and five mph."],"metadata":{"id":"DcOTggHmxMc0"}},{"cell_type":"code","execution_count":61,"metadata":{"id":"h10IvnIa1EAk","executionInfo":{"status":"ok","timestamp":1668646011023,"user_tz":300,"elapsed":10,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# Make wind level middle of range\n","split = df['Wind Level'].str.split('-', expand=True)\n","df_clean['wind_level'] = (split[0].astype(int) + split[1].astype(int)) / 2"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"1IXl3_QD1JQ7","executionInfo":{"status":"ok","timestamp":1668646011024,"user_tz":300,"elapsed":11,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# Set wind direction\n","df_clean['wind_dir'] = df['Wind Direction']"]},{"cell_type":"markdown","metadata":{"id":"yEIrpaOqUlLy"},"source":["## Trolling speed"]},{"cell_type":"code","source":["# Convert trolling speed ranges to discrete values\n","df_clean['trolling_speed']  = df['Trolling Speed']\n","mask = df['Trolling Speed'].astype(str).str.contains('to', )\n","split = df.loc[mask, 'Trolling Speed'].astype(str).str.split('to', expand=True)\n","df_clean.loc[split.index, 'trolling_speed'] = (split[0].astype(float) + split[1].astype(float)) / 2\n","df_clean['trolling_speed'] = df_clean['trolling_speed'].astype(float)"],"metadata":{"id":"UMVmYfeG3gfQ","executionInfo":{"status":"ok","timestamp":1668646011024,"user_tz":300,"elapsed":10,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":63,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FxN0bA2AUmby"},"source":["## Water Depth"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"bnKisw_A1Swh","executionInfo":{"status":"ok","timestamp":1668646011024,"user_tz":300,"elapsed":10,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"outputs":[],"source":["# Set water depth\n","df_clean['water_depth'] = df['Water Depth']"]},{"cell_type":"markdown","metadata":{"id":"HSu4X-x1U3lU"},"source":["## Fish"]},{"cell_type":"code","source":["# 'Fish Length' is good but 'Fish Size' uses ranges\n","df_clean['fish_length'] = df['Fish Length']\n","split = df.loc[~df['Fish Size'].isna(), 'Fish Size'].astype(str).str.split('to', expand=True)\n","df_clean.loc[split.index, 'fish_length'] = (split[0].astype(float) + split[1].astype(float)) / 2"],"metadata":{"id":"QiK7C4K-_mNm","executionInfo":{"status":"ok","timestamp":1668646011025,"user_tz":300,"elapsed":11,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["# Set fish type\n","df_clean['fish_type'] = df['Fish Type']"],"metadata":{"id":"2eoOzur84mlL","executionInfo":{"status":"ok","timestamp":1668646011025,"user_tz":300,"elapsed":10,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":["## Crew count"],"metadata":{"id":"hDJZtKJ8KuxE"}},{"cell_type":"markdown","source":["The number of crew members on a fishing trip influences a couple of factors. Namely, more crew members means that legally more rods can be put out and more fish are allowed to be kept. In consequence, more crew members can affect the hook-rate by inflating it.\n","\n","The crew members are split between the 'Crew Members' column and the 'Narrative' column depending on the year. The 'Crew Members' column is easiest to extract `crew_count` from. The narrative is more complicated since it includes extra information, and the formatting is not very consistent. We will need to use regex to extract `crew_count` from some of the 'Narrative' entries.\n","\n","The fisherman who created this dataset tells me that he is allowed three rods per person, but he has never put more than nine rods out. If you are over a certain age you need to have a fishing license to count towards the higher rod limit, so more people does not always guarentee more rods."],"metadata":{"id":"xrveRQ4oQXR-"}},{"cell_type":"code","source":["# Count crew in 'Crew Members'\n","\n","def count_crew_members(entry):\n","    \n","    # Always one person (self)\n","    count = 1 \n","\n","    # Ignore nans\n","    if entry is np.nan:\n","        return np.nan\n","\n","    # Ignore dogs and self\n","    ignore_names = ['Ruff', 'ruff', 'Buzz', 'buzz', 'Self', 'self']\n","\n","    # Count crew\n","    split = entry.split('/')\n","    for name in split:\n","        if name not in ignore_names:\n","            count += 1\n","    return count\n","\n","df_clean['crew_count'] = df['Crew Members'].apply(count_crew_members)"],"metadata":{"id":"dBDjJb8Ct5uS","executionInfo":{"status":"ok","timestamp":1668646011025,"user_tz":300,"elapsed":10,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# Count crew for all 'Narrative' idxs except 810-918\n","\n","# Select properly formatted 'Narrative' entries where 'Crew Members' \n","# doesn't exist\n","nar_df = df[df['Crew Members'].isna()]\n","temp1 = nar_df['Narrative'].str.extract('(^\\D*)\\d')[0]\n","temp2 = temp1.str.rstrip()\n","temp3 = temp2.str.rstrip(',')\n","temp4 = temp3.str.split('\\\\W')\n","\n","# Non-names and dogs (which, unfortunately, don't count towards the rod limit)\n","ignore_names = ['Ruff', 'ruff', 'Buzz', 'buzz', \n","                'Self', 'self', 'Start', 'start',\n","                'Big', 'and', 'got', 'Two', 'scoop', \n","                'his', 'Double', 'fish', 'the', 'lines', \n","                'bbbs', 'big', 'an', 'S', 'H', 'tangled', \n","                'El', 'net', '']\n","\n","# Count crew in 'Narrative' column\n","def count_crew_narrative(entry):\n","\n","    # Assume at least 1 person for nans\n","    if entry is np.nan or (entry[0] == '' and len(entry) == 1):\n","        return 1\n","    \n","    # Count crew (including captain)\n","    count = 1\n","    for name in entry:\n","        if name not in ignore_names:\n","            count += 1\n","    return count\n","    \n","temp5 = temp4.apply(count_crew_narrative)\n","df_clean.loc[df['Crew Members'].isna(), 'crew_count'] = temp5"],"metadata":{"id":"4TqklPHA668K","executionInfo":{"status":"ok","timestamp":1668646011025,"user_tz":300,"elapsed":9,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["# Count crew for 'Narrative' idxs 810-918\n","\n","# Each group is a section of the 'Narrative' column where all entries are\n","# formatted identically (start_idx, end_idx, split chunk containing crew)\n","groups = [\n","    (810, 821, 2),\n","    (822, 837, 1),\n","    (838, 908, 2),\n","    (909, 910, 1),\n","    (911, 914, 2)\n","]\n","\n","# Count crew for each different group\n","for group in groups:\n","    \n","    # Select pandas series by group range and split \n","    # each entry string into chunks\n","    split = df.loc[group[0] : group[1], 'Narrative'].str.split(',')\n","\n","    def split_crew(arr):\n","\n","        # Select chunk and split into a list of crew\n","        crew = arr[group[2]]\n","        crew_split = re.split(' and |-| & ', crew)\n","\n","        # Count crew (including captain)\n","        count = 1\n","        for member in crew_split:\n","            if not member.strip() ==  'self':\n","                count += 1\n","        return count\n","\n","    df_clean.loc[group[0] : group[1], 'crew_count'] = split.apply(split_crew)"],"metadata":{"id":"GsM6YgqrfE1K","executionInfo":{"status":"ok","timestamp":1668646011026,"user_tz":300,"elapsed":9,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["## Weight"],"metadata":{"id":"nYRMCfJXI_BR"}},{"cell_type":"markdown","source":["Since multiple rows represent a single day, the `hook_rate` will be biased towards days with more rows. Therefore individual datapoints should be weighted by the number of entries for a single day."],"metadata":{"id":"gjzD0pRWJBOg"}},{"cell_type":"code","source":["# Calculate weights for each row\n","\n","weights_inv = df_clean.groupby('date').size()\n","df_clean['weight'] = 1.\n","\n","def apply_weights(row): \n","    row['weight'] = 1 / float(weights_inv[row['date']])\n","    return row\n","\n","df_clean = df_clean.apply(apply_weights, axis=1)"],"metadata":{"id":"ViPHBPywJioA","executionInfo":{"status":"ok","timestamp":1668646011877,"user_tz":300,"elapsed":860,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":["## Hook-rate"],"metadata":{"id":"U41bHmW6Jpj7"}},{"cell_type":"markdown","source":["Since only days where a fish is caught are recorded, we need a metric to determine if a day is good or bad. Hooks-per-hour is probably the closest we can get to that metric"],"metadata":{"id":"u5TJg2e5Jtvr"}},{"cell_type":"code","source":["# Calculate hooks per hour\n","df_clean['hook_rate'] = df_clean['hooked'] / df_clean['hours_fishing']"],"metadata":{"id":"O-zz3svVJ4kS","executionInfo":{"status":"ok","timestamp":1668646011877,"user_tz":300,"elapsed":5,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":71,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dVnNsURn7ZWB"},"source":["## Location"]},{"cell_type":"markdown","metadata":{"id":"WiVWdkWV3R-2"},"source":["Some of the sample sizes for these locations is very small, and some aren't even on the lake! We'll drop some rows and impute small samples as `nan`"]},{"cell_type":"code","source":["# Simplify locations\n","\n","# Later locations overwrite previous locations, order by priority descending\n","df_clean['location'] = df['Location'].copy()\n","locations = [\n","    \"AuTrain\",\n","    \"White Rocks\",\n","    \"Shot Point\",\n","    \"Sand Hole\",\n","    \"Upper Harbor\",\n","    \"Lower Harbor\",\n","    \"Chocolay\",\n","    \"Lower Harbor Breakwall\",\n","    \"Lower Harbor Lighthouse\",\n","]\n","for location in locations:\n","    df_clean.loc[df.Location.str.contains(location, case=False), 'location'] = location\n","\n","# df_clean.groupby('location').size()"],"metadata":{"id":"gLUzlUnttQ3X","executionInfo":{"status":"ok","timestamp":1668646011878,"user_tz":300,"elapsed":6,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["# Seul Choix Pt isn't on lake superior, drop it\n","drop_index = df_clean[df_clean['location'] == 'Seul Choix Pt'].index\n","df_clean.drop(drop_index, inplace=True)\n","\n","# Impute nans for locations with less than 30 fish caught\n","nan_locs = ['AuTrain', 'Fairport', 'Carp', 'Humps', 'Picnic Rocks', \n","            'Thoney Point']\n","for loc in nan_locs:\n","    df_clean.loc[df_clean['location'] == loc, 'location'] = np.nan\n","\n","df_clean.groupby('location').size()"],"metadata":{"id":"ImNSc_i98L3_","executionInfo":{"status":"ok","timestamp":1668646011878,"user_tz":300,"elapsed":6,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3efc73d9-bfc4-4337-b7e1-35c718348fab"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["location\n","Chocolay                   284\n","Golden Triangle             30\n","Lower Harbor               420\n","Lower Harbor Breakwall     162\n","Lower Harbor Lighthouse    239\n","Sand Hole                   92\n","Shot Point                 538\n","Upper Harbor                72\n","White Rocks                 65\n","dtype: int64"]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","source":["# Date index dataframe"],"metadata":{"id":"1ExNhdvCd0z-"}},{"cell_type":"markdown","source":["For calculations where the weight is required (say the mean or standard deviation) we might want to simplify the math. One way is to re-index by date. We can then drop the weight since each row is a single day."],"metadata":{"id":"wKbSJO8id5uP"}},{"cell_type":"code","source":["# Impute trolling_speed to mean\n","df_clean.loc[df_clean['trolling_speed'].isna(), 'trolling_speed'] = df_clean['trolling_speed'].mean()\n","\n","# impute row 1938 fish_length to mean\n","df_clean.loc[1938, 'fish_length'] = df_clean['fish_length'].mean()"],"metadata":{"id":"ZJhwHlIg2-Yf","executionInfo":{"status":"ok","timestamp":1668646011878,"user_tz":300,"elapsed":4,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["# Group dataframe by date\n","\n","# Reduce objects/categorical by mode\n","by_date_cat = df_clean.groupby('date').agg(pd.Series.mode)\n","def reduce_arrays(row):\n","\n","    # Removes all arrays by calculating mean or selecting middle value\n","    for idx, entry in enumerate(row):\n","\n","        # Reduce numpy arrays\n","        if isinstance(entry, np.ndarray):\n","\n","            # Make empty lists nan\n","            if len(row.iloc[idx]) == 0:\n","                row.iloc[idx] = np.nan\n","            \n","            # Select mean if numeric\n","            elif isinstance(entry, float) or isinstance(entry, int):\n","                row.iloc[idx] = np.mean(entry)\n","\n","             # Select middle if not numeric\n","            else:\n","                row.iloc[idx] = np.take(entry, entry.size // 2)\n","                \n","        # Reduce datetime arrays\n","        elif isinstance(entry, pd.core.arrays.datetimes.DatetimeArray):\n","            row.iloc[idx] = entry[ len(entry) // 2]\n","\n","    return row\n","by_date_cat = by_date_cat.apply(reduce_arrays)\n","\n","# Reduce numericals by mean\n","by_date_num = df_clean.groupby('date').mean()\n","\n","# Combine numericals and categoricals, order matters,\n","# by_date_num overrides by_date_cat for certain columns\n","by_date = by_date_cat\n","for col in by_date_num:\n","    by_date[col] = by_date_num[col]\n","by_date.drop(columns='weight', inplace=True)"],"metadata":{"id":"OiudKR64iqe6","executionInfo":{"status":"ok","timestamp":1668646014094,"user_tz":300,"elapsed":2220,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["# When we grouped some of the locations became sparse, let's drop\n","# any with less than 10 days fished\n","\n","nan_locs = ['Golden Triangle']\n","for loc in nan_locs:\n","    by_date.loc[by_date['location'] == loc, 'location'] = np.nan\n","\n","by_date.groupby('location').size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaMUbCfaA4Rp","executionInfo":{"status":"ok","timestamp":1668646014095,"user_tz":300,"elapsed":6,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}},"outputId":"fdda57da-59bb-460e-8efa-839fbea82ca5"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["location\n","Chocolay                    62\n","Lower Harbor               103\n","Lower Harbor Breakwall      34\n","Lower Harbor Lighthouse     64\n","Sand Hole                   20\n","Shot Point                  58\n","Upper Harbor                16\n","White Rocks                 25\n","dtype: int64"]},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","source":["# Export data"],"metadata":{"id":"sLCq6WYLRh2P"}},{"cell_type":"code","source":["# Save un-reduced dataframes to csv\n","df_clean.to_csv(path_to_folder + 'fishing_unmerged.csv', index=False)\n","by_date.to_csv(path_to_folder + 'fishing_by_date_unmerged.csv')"],"metadata":{"id":"LRr-lH17SSQB","executionInfo":{"status":"ok","timestamp":1668646014095,"user_tz":300,"elapsed":5,"user":{"displayName":"Nathaniel Lacelle","userId":"04739549753558094557"}}},"execution_count":77,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["z3paB6LdRPdz","uraI93bw6iWI","FMRJvfstibHt","G8KOgIiS19x6","sXvDAukaykX7","X_6Xg0MNUKRc","dVnNsURn7ZWB","F27S5AV07oRg","_6IAmOwlUW8G","VmSj_y1_Uhl8","yEIrpaOqUlLy","FxN0bA2AUmby","062CFWrVU5OF","HSu4X-x1U3lU","nYRMCfJXI_BR","sLCq6WYLRh2P"],"provenance":[],"authorship_tag":"ABX9TyOphx8lgtBG8UhPZprflVEi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}